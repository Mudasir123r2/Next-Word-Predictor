# ğŸ“ Next Word Prediction - LSTM Neural Network

A deep learning application that predicts the next word in a sequence using an LSTM neural network trained on Shakespeare's Hamlet.

## ğŸŒŸ Features

- **LSTM Neural Network** with 150 and 100 units
- **Dropout Layers** for regularization (0.2)
- **Early Stopping** to prevent overfitting
- **Interactive Web Interface** built with Streamlit
- **Top-K Predictions** with confidence scores
- **Real-time Predictions**

## ğŸ—ï¸ Model Architecture

```
Input Layer (Embedding) â†’ LSTM(150) â†’ Dropout(0.2) â†’ LSTM(100) â†’ Dense(Softmax)
```

## ğŸ“Š Dataset

- **Source:** Shakespeare's Hamlet from NLTK corpus
- **Preprocessing:** Tokenization, n-gram sequence generation, padding
- **Train/Test Split:** 80/20

## ğŸš€ Quick Start

### 1. Installation

```bash
pip install -r requirements.txt
```

### 2. Run the Streamlit App

```bash
streamlit run app.py
```

The app will open at `http://localhost:8501`

## ğŸ“ Project Structure

```
Next Word Prediction/
â”œâ”€â”€ app.py                    # Streamlit application
â”œâ”€â”€ expermiments.ipynb        # Model training notebook
â”œâ”€â”€ next_word_model.h5        # Trained model
â”œâ”€â”€ tokenizer.pickle          # Tokenizer object
â”œâ”€â”€ hamlet.txt                # Training data
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ DEPLOYMENT_GUIDE.md       # Deployment instructions
â””â”€â”€ README.md                 # This file
```

## ğŸ¯ How It Works

1. **Input:** User enters a text phrase
2. **Tokenization:** Text is converted to sequences
3. **Prediction:** LSTM model predicts probability distribution
4. **Output:** Top 5 most likely next words with confidence scores

## ğŸ’» Usage Example

**Input:** `"To be, or not to be, that is"`

**Output:**
1. **the** - 45.23%
2. **a** - 23.45%
3. **question** - 12.34%
4. **not** - 8.76%
5. **all** - 5.43%

## ğŸ› ï¸ Technologies Used

- **TensorFlow/Keras** - Deep learning framework
- **Streamlit** - Web application framework
- **NumPy** - Numerical computing
- **NLTK** - Natural language processing
- **Scikit-learn** - Train/test splitting

## ğŸ“ˆ Model Performance

- **Training:** 100 epochs (with early stopping)
- **Validation Monitoring:** val_loss
- **Patience:** 10 epochs
- **Optimizer:** Adam
- **Loss:** Categorical Crossentropy

## ğŸŒ Deployment

See [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md) for detailed deployment instructions on:
- Streamlit Community Cloud (FREE)
- Heroku
- AWS EC2
- Docker

## ğŸ”® Future Enhancements

- [ ] Add multiple model options (GPT-2, BERT)
- [ ] Support for longer context windows
- [ ] Multi-word prediction
- [ ] Fine-tuning on custom datasets
- [ ] API endpoint for integrations
- [ ] Mobile-responsive design improvements

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ‘¤ Author

Created as a demonstration of LSTM-based next word prediction.

## ğŸ™ Acknowledgments

- Shakespeare's Hamlet dataset from NLTK
- Streamlit for the amazing framework
- TensorFlow team for the deep learning tools

---

**Happy Predicting! ğŸ‰**
